{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtoolbox.transform import Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     3,
     14,
     44
    ]
   },
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def change_2848_loader(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    \n",
    "    if img.size[0] < 2800:\n",
    "        return img\n",
    "    else:\n",
    "        img_pad = np.zeros((img.size[1] + 800, img.size[0], 3), dtype=np.uint8)\n",
    "        img_pad[400:400+2848, 160:] = np.asanyarray(img)[:, :-160]\n",
    "        img = Image.fromarray(img_pad)\n",
    "        return img\n",
    "\n",
    "class DatasetFromCSV(Dataset):\n",
    "    def __init__(self, image_root, csv_path, transforms=None, loader=change_2848_loader):\n",
    "        \n",
    "        self.image_root = image_root\n",
    "        \n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.labels = np.asarray(self.data.iloc[:, 2:])\n",
    "        \n",
    "        # process image name\n",
    "        imgs = []\n",
    "        files_names = np.array(self.data.iloc[:, 0])\n",
    "        for img in files_names:\n",
    "            imgs.append(os.path.join(self.image_root, str(img)+'.png'))\n",
    "        \n",
    "        self.images = imgs\n",
    "        self.transforms = transforms\n",
    "        self.loader = loader\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        label = self.labels[index]\n",
    "        img = self.images[index]\n",
    "        img = self.loader(img)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.index)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.rstrip('\\n')\n",
    "            words = line.split()\n",
    "            imgs.append((words[0],int(words[1])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "transform_color = [transforms.ColorJitter(brightness=0.5),\n",
    "                       transforms.ColorJitter(contrast=0.5)\n",
    "                      ]\n",
    "transform_affine = [\n",
    "#                     transforms.RandomAffine(0, shear=20),\n",
    "                    transforms.RandomAffine(0, scale=(0.95, 1.05)),\n",
    "                    transforms.RandomAffine(0, translate=(0.05, 0.05)),\n",
    "                    transforms.RandomAffine(degrees=20)]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.Resize(size=(460), interpolation=Image.LANCZOS),\n",
    "#                 transforms.CenterCrop(size=400),\n",
    "                transforms.RandomApply(transform_affine, p=0.5),\n",
    "                transforms.RandomHorizontalFlip(p=0.5), #随机水平翻转图片\n",
    "                transforms.RandomApply(transform_color, p=0.5),\n",
    "#                 Cutout(0.5, scale=(0.02, 0.2), ratio=(0.4, 2.5)),\n",
    "                transforms.CenterCrop(size=480),\n",
    "                transforms.ToTensor(), #将图片变成 Tensor，并且把数值normalize到[0,1]    \n",
    "#                 transforms.Normalize([0.320, 0.197, 0.103], [0.317, 0.206, 0.128])\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到均值与方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49825245 0.52724576 0.38957652] [0.22746916 0.2125958  0.23409073]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((600, 600)), # 可以改成你图片近似大小或者模型要求大小\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# train_data= MyDataset(\"My_data/Training_Set/Training/\", \"My_data/Training_Set/RFMiD_Training_Labels.csv\", train_transform)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_data,batch_size=1000, shuffle=True)\n",
    "\n",
    "batch_size = 500\n",
    "root = \"./My_data/\"\n",
    "train_dataset = MyDataset(txt=root + 'train.txt', transform=train_transform)\n",
    "valid_dataset = MyDataset(txt=root + 'valid.txt', transform=train_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "train = iter(train_loader).next()[0]  # 500张图片的mean std\n",
    "train_mean = np.mean(train.numpy(), axis=(0, 2, 3))\n",
    "train_std = np.std(train.numpy(), axis=(0, 2, 3))\n",
    "\n",
    "print(train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.498 0.527 0.39 ] [0.227 0.213 0.234]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(train_mean, 3), np.round(train_std, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -> 000\n",
      "epoch -> 020\n",
      "epoch -> 040\n",
      "epoch -> 060\n",
      "epoch -> 080\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"epoch -> {i:>03d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchg]",
   "language": "python",
   "name": "conda-env-torchg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
